{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ad-Rian815/Unza_journal_key_word_classification/blob/main/Automatic_Classification_Of_Key_Words_Associated_with_articles_on_Unza_journals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9m5C546ACXEM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Business Understanding\n"
      ],
      "metadata": {
        "id": "q5BHIcKZFccf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Problem Statement\n",
        "Currently, keywords associated with research articles in UNZA journals are not automatically organized or classified. This makes it difficult for researchers, students, and librarians to quickly identify relevant articles or track research trends. A manual process is time-consuming, inconsistent, and limits the usefulness of the institutional repository. Navigation of journals will be a piece of cake!"
      ],
      "metadata": {
        "id": "zzXRR53RcVZn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Business Objectives\n",
        "The goal of this project is to build a system that can automatically classify keywords from articles into meaningful categories (e.g., *Agriculture, Medicine, Computer Science*).  \n",
        "\n",
        "From a real-world perspective, success means:\n",
        "- Improving searchability and retrieval of research articles.\n",
        "- Helping researchers discover related works faster.\n",
        "- Supporting administrators in analyzing research output trends at UNZA."
      ],
      "metadata": {
        "id": "T91ZAsmoREBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.3 Data Mining Goal\n",
        "  \n",
        "  The technical approach to achieving these objectives is structured into the following data mining goals:\n",
        "\n",
        "   1.Classification Model Development: A classification model will be built to  categorize article keywords into predefined classes.\n",
        "\n",
        "  2.Text Preprocessing: The raw text data will be prepared for machine learning using standard preprocessing techniques, including tokenization, stop-word removal, and TF-IDF (Term          Frequency-Inverse Document Frequency) for vectorization.\n",
        "\n",
        "  3.Algorithm Experimentation: The performance of several classification algorithms will be evaluated to determine the most effective one. The algorithms to be tested include Naïve          Bayes,   Support Vector Machines (SVM), and Decision Trees.\n",
        "  \n",
        "  To wrap things up, the main goal of this project is to build a machine learning model that can automatically classify article keywords. We've broken the work down into two key           parts. First, we'll focus on data preparation by cleaning the text using tokenization and stop-word removal, and then we'll use TF-IDF to turn everything into numbers for the models     to work with.\n",
        "  \n",
        "  For the second part, we'll experiment with different algorithms like Naïve Bayes, SVM, and Decision Trees. By testing them with metrics like precision and F1-score, then we'll           figure out which one is the most accurate. We're hoping that by following these steps, we can successfully create a model that not only classifies keywords effectively but also          shows we've got a solid grasp of the data mining process.\n",
        "\n",
        "   Summary: The workflow involves two main stages.\n",
        "  First, text preprocessing to clean and transform raw keywords into numerical representations.\n",
        "  Second, experimentation with multiple algorithms to identify the most accurate and robust classifier.\n",
        "\n",
        "    1.3.1 Data Preparation\n",
        "       Before building the model the data will be,\n",
        "       Tokenized into smaller units.\n",
        "       Cleaned by removing stop words and irrelevant terms.\n",
        "       Converted into numerical representations using TF-IDF for input into machine learning models."
      ],
      "metadata": {
        "id": "uxUYX_Y1WMRM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Project Success Criteria\n",
        "- The model should achieve at least **80% accuracy** on the test dataset.\n",
        "- The classification results must be **interpretable and consistent** across different domains.\n",
        "- The classification outputs are clear and be easily explained to non-technical stakeholders.\n",
        "- The system should reduce the time required to organize keywords compared to manual methods."
      ],
      "metadata": {
        "id": "rnDULKNcWVKB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Understanding\n"
      ],
      "metadata": {
        "id": "UajRKSlpWt91"
      }
    }
  ]
}